{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir # to get the files and directories\n",
    "from os.path import join # to joint base path with sub path\n",
    "import numpy as np # numpy library will help us to work with the numbers and arrays\n",
    "import matplotlib.pyplot as plt # to visualize/plot the images\n",
    "import cv2 # handle the images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    ")\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./The IQ-OTHNCCD lung cancer dataset/\"\n",
    "# . -> current working directory\n",
    "categories = listdir(base_path)\n",
    "print(categories)\n",
    "# We have 3 classes: Benign, Malignant, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}  # to store each class of images in one dictionary\n",
    "for category in categories:\n",
    "    images[category] = (\n",
    "        []\n",
    "    )  # each class has more than one images and we'll store all in one list\n",
    "    category_path = join(base_path, category)\n",
    "    for img_name in listdir(category_path):\n",
    "        img_path = join(category_path, img_name)\n",
    "        img = cv2.imread(\n",
    "            img_path, cv2.IMREAD_GRAYSCALE\n",
    "        )  # read images in grayscale (one chanel)\n",
    "        images[category].append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(target_size):\n",
    "    for category in categories:\n",
    "        # We need to use enumerate to get the index because we want to edit on the original list and we can't do that without index\n",
    "        for index, img in enumerate(images[category]):\n",
    "            if img.shape != target_size:\n",
    "                images[category][index] = cv2.resize(img, target_size)\n",
    "\n",
    "resize_images((128, 128))\n",
    "# We choose the majority shape (512, 512) and shrink the image to (128, 128) because training the model with (512, 512) images takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays for efficient numerical computations\n",
    "for category in categories:\n",
    "    images[category] = np.array(images[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convert dict_values to list then we'll have list of arrays\n",
    "X = np.concatenate(list(images.values()))\n",
    "y = np.concatenate([[category]*len(images[category]) for category in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_class = [\"Malignant cases\", \"Non-Malignant cases\"]\n",
    "y_one_class = np.where(y == one_class[0], one_class[0], one_class[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_class, test_size=0.3, stratify=y_one_class, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,*X_train[0].shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Input Layer\n",
    "model.add(Input(shape=X_train[0].shape))\n",
    "# Hidden Layers\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), name=\"conv2d_1\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), name=\"max2d_1\"))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), name=\"conv2d_2\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), name=\"max2d_2\"))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=(3, 3), name=\"conv2d_3\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), name=\"max2d_3\"))\n",
    "\n",
    "model.add(Flatten(name=\"flatten\"))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1, activation=\"sigmoid\", name=\"out\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_encoded,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test_encoded),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
